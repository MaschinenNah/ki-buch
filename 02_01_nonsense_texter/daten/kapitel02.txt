Wissen Sie, was ein Zeichtstern, ein Nichtspunkt oder ein Duftgebück ist? Oder haben Sie etwa schon einmal wirrwartend fenstige Wunschwellen durchhoffnet? Vermutlich nicht! Auch wenn diese rätselhafen Wörter offenbar deutschsprachig sind, können wir über deren Bedeutung nur mutmaßen. Und doch haben sie etwas gemeinsam: Sie alle wurden von einem Algorithmus erdacht, den wir in diesem Kapitel vorstellen – und dieser ist imstande, weitaus mehr zu leisten, als unsinnige Wörter zu erdichten.
Ob Zeitungsmeldung, Bedienungsanleitung oder Roman: Wann immer Menschen einen Text lesen, steht der Sinn des Geschriebenen im Vordergrund. Computer allerdings wissen nichts über Texte und deren Bedeutung. Für einen Rechner sind Texte lediglich Zeichenketten, genauer gesagt: Abfolgen von Zahlen. Jede Zahl steht für ein Zeichen. Die Übersetzung von Zeichen in Zahlen und zurück regeln meist der ASCII- oder der Unicode-Standard.
Dieses Kapitel stellt eine Erfindung vor, die der russische Mathematiker Andrei Andrejewitsch Markow um 1919 gemacht hat. Sein Markow-Prozess lässt sich sich besonders gut auf Zeichenketten anwenden. Dieser untersucht gegebene Texte im Hinblick auf eine einzige Eigenschaft: Welche Zeichen folgen darin aufeinander und welche nicht? In einem zweiten Schritt kann der Markow-Prozess Texte zusammenbauen, welche diese Eigenschaft des Originals reproduzieren – mit erstaunlichen und belustigenden Ergebnissen.
Im einfachsten Fall besitzt ein Markow-Prozess kein Gedächtnis. Das bedeutet, dass die Wahrscheinlichkeit für das Auftreten eines bestimmten nächsten Zeichens unabhängig von den vorherigen Zeichen ist. Wenn Sie einen deutschsprachigen Text mittels eines solchen erinnerungslosen Markow-Prozesses untersuchen, werden Sie feststellen, dass die Häufigkeit des Buchstabens E etwa 15 % beträgt. Seltene Buchstaben wie X, Y oder Q hingegen kommen auf Häufigkeiten von wenigen Prozentbruchteilen.
Interessanter wird es, wenn der Algorithmus zur Bestimmung der Wahrscheinlichkeit eines nächsten Zeichens die vorherigen Zeichen berücksichtigt. Der Grad des Markow-Prozesses legt die Anzahl der berücksichtigten vorangegangenen Zeichens fest. Grad 1 bedeutet, dass nur das jeweils letzte Zeichen zählt; ein Markow-Prozess zweiten Grades interessiert sich für die letzten beiden Zeichen und so fort.
Die Abbildung 1.1 veranschaulicht das Prinzip anhand eines Markow-Prozesses ersten Grades und eines aus vier Wörtern bestehenden Textbeispiels: HAUS, LAUS, LAUB und AUA. Der Übergangsgraph und die Tabelle zeigen:
Auf ein H oder L folgt immer ein A.
Auf ein A folgt immer ein U.
Auf ein U kann ein S, ein B oder ein A folgen.
Damit haben wir die zulässigen Übergänge vollständig beschrieben. Die Produktion eines neuen Wortes nach den so beschriebenen Regeln dann wie folgt ab:
Starten Sie an einem beliebigen Knoten des Übergangsgraphen, beispielsweise mit dem A.
Nach dem A folgt immer ein U.
Das U bietet drei Anschlussmöglichkeiten: S, B und A. In diesem Fall suchen Sie sich eine aus oder lassen Sie das Los entscheiden! Auf diese Weise können Sie etwa folgende Ketten bilden: AU, AUS, AUB, AUA, AUAUS, AUAUB…
Ensprechendes gilt, wenn Sie mit einem H starten. Dann kann der Algorithmus HA, HAU, HAUS, HAUHAU, HAUAUB et cetera produzieren.
Nach diesem Prinzip lassen sich auch auf Basis umfangreicherer Textbeispiele neue Texte beliebiger Länge erzeugen. Der Markow-Prozess weiß zwar nichts über Sprachen und Wörter, kann aber ausgehend von entsprechenden Textquellen eindeutig deutschsprachige Wörter wie transportig, wiedenartig, überhaftlich und deineswegs erdenken oder englischsprachigen Unsinn schreiben: my deal happily doubt what he two.
Dieses Kapitel zeigt zwei konkrete Anwendungen von Markow-Prozessen: Der „Nonsense-Texter“ produziert neue Texte aufgrund von gegebenen Textquellen. Das Programm „Wörter vorschlagen“ bietet eine simple Satzvervollständigung.
Im Nonsense-Texter wählen Sie mittels Dropdown-Menü die Textquelle und den Grad des Markow-Prozesses. Ein Klick auf die Schaltfläche TEXT LERNEN startet die Untersuchung des gewählten Textes. Wenn die Untersuchung abgeschlossen ist, zeigt das Programm alle gefundenen Übergänge nach dem in Abbildung 1.1 vorgestellten Schema an: as_a -> o|i bedeutet zum Beispiel, dass nach „as a“ ein „o“ oder ein „i“ folgen kann. Der Einfachheit halber ignoriert der Nonsense-Texter Unterschiede zwischen Groß- und Kleinschreibung.
Mit einem Klick auf die Schaltfläche TEXT ERZEUGEN produziert das Programm mittels der gelernten Übergänge einen Nonsense-Text und zeigt diesen an. Jedes Mal, wenn es mehrere Anschlussmöglichkeiten  gibt, wählt der Nonsense-Texter per Zufall eine der gegebenen Möglichkeiten aus. Aus diesem Grund bekommen Sie bei jedem Druck auf die Schaltfläche einen neuen Text geliefert.
Was haben ein U-Bahn-Netz, eine elektronische Schaltung und Verwandschaftsverhältnisse gemeinsam? Sie alle lassen sich mittels sogenannter Graphen darstellen. Graphen sind mathematische Modelle für netzartige Strukturen. Sie sind zusammengesetzt aus Knoten und Kanten.
Wenn der Graph ein U-Bahn-Netz darstellen soll, dann stehen die Knoten für U-Bahn-Stationen und die Kanten für Gleisverbindungen. 
Bei einem Schaltplan repräsentieren Knoten die Bauelemente und die Kanten Leiterbahnen oder Kabel. 
Soll ein Graph Verwandschaftsverhältnisse abbilden, stehen die Knoten für Personen und die Kanten für Verbindungen wie Elternschaft, Heirat oder Adoption.
Graphen haben sich als leistungsfähig erwiesen, wenn es darum geht, Übersicht in komplexe Zusammenhänge zu bringen und diese einheitlich darzustellen. Auch bei vielen in diesem Buch vorgestellten Problemen ist es hilfreich, sie als Graphenprobleme zu verstehen. Wir werden daher in diesem und zwei weiteren Kästen in den Kapiteln 4 und 5 die wichtigsten Begriffe der Graphentheorie vorstellen.
Auch die möglichen Verläufe einer Schachpartie und die Bedienung eines Getränkeautomaten lassen sich mittels Graphen darstellen. Dabei repräsentieren Knoten die Zustände und Kanten die Zustandsübergänge.
Bei einer Schachpartie stehen die Knoten für Stellungen der Figuren auf dem Brett und die Kanten für gültige Züge.
Bei der Bedienung des Getränkeautomaten könnten die Knoten Zustände wie „Getränk gewählt“, „Münze eingeworfen“ oder „Getränk ausgegeben“ repräsentieren. Die Kanten sind dann Aktionen wie „Getränk wählen“, „Münze einwerfen“ oder „Getränk ausgeben“.
Die Darstellung solch veränderlicher Systeme in Form eines Graphen ist sehr nützlich. In der Informatik nennen wir das auch einen Zustandautomaten (engl. State Machine). Die folgende Abbildung zeigt ein sehr einfaches Beispiel. Es gibt lediglich zwei Zustände: „Blume traurig“ und „Blume fröhlich“. Der einzige Zustandsübergang ist hier „gießen“:
Auch ein Markow-Prozess lässt sich als Graph verstehen. Zustände könnten bei einem Markow-Prozess dritten Grades die zuletzt erschienenen drei Buchstaben sein. Die Kanten würden dann jeweils für die Anfügung eines einzelnen Buchstabens stehen.